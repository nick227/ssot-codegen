# AI Chat - Complete Integration Example

**Complete chat application showcasing the full power of SSOT:**

âœ… **WebSockets** - Real-time message streaming  
âœ… **AI Plugins** - GPT-4, Claude, Gemini integration  
âœ… **React Hooks** - Type-safe data management  
âœ… **UI Templates** - Beautiful chat interface  
âœ… **Schema Annotations** - @@realtime for instant updates  

---

## ğŸ¯ What This Example Demonstrates

### 1. Schema with Annotations
```prisma
model Message {
  id             String       @id @default(cuid())
  content        String
  role           MessageRole
  conversationId String
  
  /// @realtime(subscribe: ["list"], broadcast: ["created", "updated", "deleted"])
}
```

### 2. Plugin Configuration
```typescript
plugins: [
  new OpenAIPlugin({
    defaultModel: 'gpt-4-turbo',
    enableUsageTracking: true
  }),
  new ChatPlugin({
    enableWebSocket: true,
    enableMemory: true
  })
]
```

### 3. WebSocket Configuration
```typescript
websocket: {
  enabled: true,
  pubsub: {
    models: {
      Message: {
        subscribe: ['list'],
        broadcast: ['created']
      }
    }
  }
}
```

### 4. UI Configuration
```typescript
pages: [{
  path: 'chats/[id]',
  type: 'custom',
  sections: [{
    type: 'custom',
    components: [{
      type: 'ChatInterface',
      props: { conversationId: 'params.id' }
    }]
  }]
}]
```

---

## ğŸš€ Quick Start

### Step 1: Generate Project

```bash
# Navigate to this example
cd examples/ai-chat-complete

# Generate complete project
npx ssot-gen generate schema.prisma --config ssot.config.ts --output ./generated

# Generate UI
npx ssot-gen ui --config ssot.ui.config.ts --output ./generated/src
```

### Step 2: Setup Environment

```bash
cd generated

# Create .env file
cat > .env << EOF
DATABASE_URL="postgresql://user:pass@localhost:5432/chat"
OPENAI_API_KEY="sk-your-openai-key-here"
EOF

# Install dependencies
pnpm install

# Setup database
pnpm prisma migrate dev --name init
pnpm prisma generate
```

### Step 3: Run Application

```bash
# Terminal 1: Start API server
pnpm dev

# Terminal 2: Start WebSocket server
pnpm dev:ws

# Terminal 3: Start frontend
cd ../frontend
pnpm dev
```

---

## ğŸ“¦ What Gets Generated

### Backend Files

```
generated/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ chat.service.ts       # AI + storage orchestration
â”‚   â”‚   â”œâ”€â”€ chat.controller.ts    # HTTP endpoints
â”‚   â”‚   â”œâ”€â”€ chat.routes.ts        # Route registration
â”‚   â”‚   â”œâ”€â”€ chat.gateway.ts       # WebSocket gateway
â”‚   â”‚   â”œâ”€â”€ chat.types.ts         # Type definitions
â”‚   â”‚   â”œâ”€â”€ react/
â”‚   â”‚   â”‚   â”œâ”€â”€ useChat.ts        # React hook
â”‚   â”‚   â”‚   â””â”€â”€ useChatWebSocket.ts # WebSocket hook
â”‚   â”‚   â””â”€â”€ ui/
â”‚   â”‚       â”œâ”€â”€ ChatInterface.tsx  # Complete chat UI
â”‚   â”‚       â”œâ”€â”€ MessageList.tsx    # Message display
â”‚   â”‚       â”œâ”€â”€ MessageInput.tsx   # Message input
â”‚   â”‚       â””â”€â”€ ConversationList.tsx # Conversation list
â”‚   â”‚
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â””â”€â”€ openai.provider.ts # OpenAI integration
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ openai.service.ts  # High-level AI API
â”‚   â”‚
â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”œâ”€â”€ gateway.ts             # WebSocket server
â”‚   â”‚   â””â”€â”€ client.ts              # WebSocket client
â”‚   â”‚
â”‚   â””â”€â”€ gen/
â”‚       â”œâ”€â”€ sdk/                   # Type-safe SDK
â”‚       â””â”€â”€ hooks/                 # React Query hooks
```

### Frontend Files

```
src/app/
â”œâ”€â”€ page.tsx                # Home page
â”œâ”€â”€ chats/
â”‚   â”œâ”€â”€ page.tsx           # Conversation list
â”‚   â””â”€â”€ [id]/page.tsx      # Chat interface
â”‚
â””â”€â”€ components/
    â””â”€â”€ ssot/
        â”œâ”€â”€ ChatInterface.tsx
        â”œâ”€â”€ MessageList.tsx
        â””â”€â”€ MessageInput.tsx
```

---

## ğŸ”Œ How It All Wires Together

### Data Flow

```
User types message
    â†“
MessageInput component
    â†“
useChat hook (React Query)
    â†“
WebSocket.emit('send-message')
    â†“
Chat Gateway (WebSocket server)
    â†“
Chat Service
    â”œâ”€â†’ Save user message (Prisma)
    â”œâ”€â†’ Get conversation history
    â”œâ”€â†’ Call AI provider (OpenAI)
    â”œâ”€â†’ Save AI response (Prisma)
    â””â”€â†’ Broadcast updates (WebSocket)
    â†“
useChatWebSocket hook receives update
    â†“
React Query cache updated
    â†“
MessageList re-renders with new messages
```

### Component Integration

```typescript
// Chat interface uses:
import { useChat } from '@/chat/react/useChat'              // React hook
import { useChatWebSocket } from '@/chat/react/useChatWebSocket' // WebSocket hook
import { MessageList } from '@/chat/ui/MessageList'         // UI component
import { MessageInput } from '@/chat/ui/MessageInput'       // UI component

function ChatInterface({ conversationId }) {
  // Data management (React Query)
  const { messages, sendMessage } = useChat(conversationId)
  
  // Real-time updates (WebSocket)
  useChatWebSocket(conversationId)
  
  return (
    <>
      <MessageList messages={messages} />
      <MessageInput onSend={sendMessage} />
    </>
  )
}
```

---

## ğŸ§© Architecture Layers

### Layer 1: Database (Prisma)
```prisma
model Message {
  /// @realtime(subscribe: ["list"], broadcast: ["created"])
}
```

### Layer 2: Plugins
```typescript
plugins: [
  new OpenAIPlugin(),  // AI provider
  new ChatPlugin()     // Chat orchestration
]
```

### Layer 3: WebSocket
```typescript
websocket: {
  pubsub: {
    models: { Message: { broadcast: ['created'] } }
  }
}
```

### Layer 4: SDK + Hooks
```typescript
// Generated hooks
const { messages } = useMessages({ conversationId })
const { mutate: createMessage } = useCreateMessage()
```

### Layer 5: UI Components
```typescript
<ChatInterface conversationId={id} />
```

---

## ğŸ¨ Features

### Real-time Messaging
- WebSocket connection for instant delivery
- Optimistic updates (message shows immediately)
- Automatic reconnection
- Message batching for performance

### AI Integration
- Multiple providers (OpenAI, Claude, Gemini)
- Configurable per conversation
- Custom system prompts
- Temperature control
- Token usage tracking
- Cost estimation

### Conversation Management
- Create/delete conversations
- Conversation history
- Multi-participant support
- Conversation types (DIRECT, GROUP, AI)

### Modern UI
- Beautiful chat interface
- Message bubbles (user vs AI)
- Typing indicators
- Read receipts
- Auto-scroll to bottom
- Mobile responsive

---

## âš™ï¸ Configuration Options

### AI Model Selection

```typescript
// In ssot.config.ts
new OpenAIPlugin({
  defaultModel: 'gpt-4-turbo',  // or 'gpt-3.5-turbo'
  enableUsageTracking: true,
  enableCostEstimation: true
})

// Per conversation (in database)
conversation.model = 'gpt-4'
conversation.temperature = 0.7
conversation.systemPrompt = 'You are a helpful assistant'
```

### WebSocket Settings

```typescript
websocket: {
  port: 3001,
  path: '/ws',
  reconnect: {
    maxAttempts: 10,
    backoff: 'exponential'
  },
  batching: {
    enabled: true,
    flushInterval: 100
  }
}
```

---

## ğŸ§ª Testing

```bash
# Start backend
pnpm dev

# Start WebSocket server
pnpm dev:ws

# Open browser
http://localhost:3000/chats

# Create a new chat
# Send a message
# Watch AI respond in real-time!
```

---

## ğŸ” Authentication

Add auth to secure conversations:

```typescript
// ssot.config.ts
plugins: [
  new JWTPlugin(),
  new OpenAIPlugin(),
  new ChatPlugin()
]

// ssot.ui.config.ts
pages: [{
  path: 'chats',
  requiresAuth: true,  // Require login
  roles: ['USER']      // Optional role check
}]
```

---

## ğŸ“Š Usage Tracking

Chat plugin automatically tracks:
- Tokens used (prompt + completion)
- Estimated cost per message
- Model used
- Response latency

All stored in `message.metadata`:

```typescript
{
  usage: {
    promptTokens: 150,
    completionTokens: 75,
    totalTokens: 225,
    estimatedCost: 0.00675
  },
  model: 'gpt-4-turbo',
  latency: 1234,
  finishReason: 'stop'
}
```

---

## ğŸš€ Next Steps

1. âœ… Generate the project
2. âœ… Configure environment variables
3. âœ… Start servers
4. âœ… Test chat functionality
5. ğŸ¨ Customize UI
6. ğŸ¤– Add more AI providers
7. ğŸ” Add authentication
8. ğŸ“± Deploy!

---

## ğŸ’¡ Extend This Example

### Add Voice Input
```typescript
plugins: [
  new OpenAIPlugin(),
  new DeepgramPlugin(),  // Voice-to-text
  new ElevenLabsPlugin() // Text-to-voice
]
```

### Add Image Generation
```typescript
// Use DALL-E for image generation
const image = await openai.images.generate({
  prompt: message.content,
  model: 'dall-e-3'
})
```

### Add RAG (Retrieval Augmented Generation)
```typescript
// Add embeddings for semantic search
const embedding = await openaiService.embed(message.content)
// Search similar messages
// Include in context
```

---

## ğŸ“š Learn More

- [Plugin System](../../docs/PLUGIN_GUIDE.md)
- [WebSocket Integration](../../docs/RLS_WEBSOCKET_INTEGRATION.md)
- [UI Configuration](../../docs/UI_CONFIGURATION_GUIDE.md)
- [React Hooks](../../docs/SDK_HOOK_CONTRACT_LOCKED.md)

---

## âœ¨ This is the Power of SSOT!

**One schema, one config, complete application!** ğŸš€

