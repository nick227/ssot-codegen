/**
 * Chatbot API Generator
 * 
 * Generates backend API endpoints for chatbot with OpenAI integration
 * Creates:
 * - POST /api/chat - Send message and get AI response
 * - GET /api/messages - Get message history
 * - WebSocket support for real-time (optional)
 */

import type { ProjectConfig } from '../prompts.js'
import type { ParsedModel } from '../ui-generator.js'
import fs from 'node:fs'
import path from 'node:path'

interface ChatbotAPIConfig {
  hasOpenAI: boolean
  messageModel: ParsedModel
  userModel: ParsedModel
}

/**
 * Generate chatbot API endpoints
 */
export function generateChatbotAPI(
  projectPath: string,
  config: ProjectConfig,
  apiConfig: ChatbotAPIConfig
): void {
  const srcDir = path.join(projectPath, 'src')
  const routesDir = path.join(srcDir, 'routes')
  
  fs.mkdirSync(routesDir, { recursive: true })
  
  // Generate chat routes
  fs.writeFileSync(
    path.join(routesDir, 'chat.ts'),
    generateChatRoutes(config, apiConfig)
  )
  
  // Generate chat service (business logic)
  fs.writeFileSync(
    path.join(srcDir, 'chat-service.ts'),
    generateChatService(config, apiConfig)
  )
  
  // Update main app file to include routes
  updateAppWithChatRoutes(projectPath, config.framework)
}

/**
 * Generate chat routes
 */
function generateChatRoutes(config: ProjectConfig, apiConfig: ChatbotAPIConfig): string {
  const { messageModel, hasOpenAI } = apiConfig
  
  if (config.framework === 'express') {
    return `/**
 * Generated by SSOT CodeGen - Chatbot API Routes
 * Chat endpoints with ${hasOpenAI ? 'OpenAI' : 'mock'} integration
 */

import { Router } from 'express'
import { ChatService } from '../chat-service.js'

const router = Router()
const chatService = new ChatService()

/**
 * POST /api/chat
 * Send a message and get AI response
 */
router.post('/chat', async (req, res) => {
  try {
    const { message, userId } = req.body
    
    if (!message || !userId) {
      return res.status(400).json({
        error: 'Missing required fields: message, userId'
      })
    }
    
    // Save user message
    const userMessage = await chatService.saveMessage({
      content: message,
      senderId: userId,
      isBot: false
    })
    
    // Get AI response
    const botResponse = await chatService.getBotResponse(message, userId)
    
    // Save bot message
    const botMessage = await chatService.saveMessage({
      content: botResponse,
      senderId: 0, // Bot user ID
      isBot: true
    })
    
    res.json({
      userMessage,
      botMessage
    })
  } catch (error) {
    console.error('Chat error:', error)
    res.status(500).json({
      error: 'Failed to process message',
      details: (error as Error).message
    })
  }
})

/**
 * GET /api/messages
 * Get message history
 */
router.get('/messages', async (req, res) => {
  try {
    const { userId, limit = 50 } = req.query
    
    const messages = await chatService.getMessageHistory({
      userId: userId ? Number(userId) : undefined,
      limit: Number(limit)
    })
    
    res.json(messages)
  } catch (error) {
    console.error('Get messages error:', error)
    res.status(500).json({
      error: 'Failed to fetch messages'
    })
  }
})

export { router as chatRouter }
`
  } else {
    // Fastify
    return `/**
 * Generated by SSOT CodeGen - Chatbot API Routes (Fastify)
 * Chat endpoints with ${hasOpenAI ? 'OpenAI' : 'mock'} integration
 */

import type { FastifyInstance } from 'fastify'
import { ChatService } from '../chat-service.js'

export async function chatRoutes(fastify: FastifyInstance) {
  const chatService = new ChatService()
  
  /**
   * POST /api/chat
   * Send a message and get AI response
   */
  fastify.post('/api/chat', async (request, reply) => {
    const { message, userId } = request.body as any
    
    if (!message || !userId) {
      return reply.status(400).send({
        error: 'Missing required fields: message, userId'
      })
    }
    
    try {
      // Save user message
      const userMessage = await chatService.saveMessage({
        content: message,
        senderId: userId,
        isBot: false
      })
      
      // Get AI response
      const botResponse = await chatService.getBotResponse(message, userId)
      
      // Save bot message
      const botMessage = await chatService.saveMessage({
        content: botResponse,
        senderId: 0,
        isBot: true
      })
      
      return { userMessage, botMessage }
    } catch (error) {
      fastify.log.error(error)
      return reply.status(500).send({
        error: 'Failed to process message',
        details: (error as Error).message
      })
    }
  })
  
  /**
   * GET /api/messages
   * Get message history
   */
  fastify.get('/api/messages', async (request, reply) => {
    const { userId, limit = 50 } = request.query as any
    
    try {
      const messages = await chatService.getMessageHistory({
        userId: userId ? Number(userId) : undefined,
        limit: Number(limit)
      })
      
      return messages
    } catch (error) {
      fastify.log.error(error)
      return reply.status(500).send({
        error: 'Failed to fetch messages'
      })
    }
  })
}
`
  }
}

/**
 * Generate chat service with OpenAI integration
 */
function generateChatService(config: ProjectConfig, apiConfig: ChatbotAPIConfig): string {
  const { hasOpenAI, messageModel } = apiConfig
  
  const openAIImport = hasOpenAI 
    ? "import OpenAI from 'openai'"
    : ''
  
  const openAIInit = hasOpenAI
    ? `
  private openai: OpenAI
  
  constructor() {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    })
  }
`
    : `
  constructor() {
    // No OpenAI integration
  }
`
  
  const botResponseMethod = hasOpenAI
    ? `
  /**
   * Get AI response using OpenAI
   */
  async getBotResponse(userMessage: string, userId: number): Promise<string> {
    try {
      // Get conversation history for context
      const history = await this.getMessageHistory({ userId, limit: 10 })
      
      // Build messages array for OpenAI
      const messages = [
        {
          role: 'system' as const,
          content: 'You are a helpful assistant. Provide concise, friendly responses.'
        },
        ...history.map((msg: any) => ({
          role: msg.isBot ? 'assistant' as const : 'user' as const,
          content: msg.content
        })),
        {
          role: 'user' as const,
          content: userMessage
        }
      ]
      
      // Call OpenAI API
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages,
        temperature: 0.7,
        max_tokens: 500
      })
      
      return completion.choices[0]?.message?.content || 'Sorry, I could not generate a response.'
    } catch (error) {
      console.error('OpenAI error:', error)
      return 'Sorry, I encountered an error. Please try again.'
    }
  }
`
    : `
  /**
   * Get bot response (mock - no OpenAI)
   * 
   * ðŸ’¡ To use real AI:
   * 1. Select "OpenAI Integration" plugin during setup
   * 2. Add OPENAI_API_KEY to .env
   * 3. Regenerate with: npm run generate
   */
  async getBotResponse(userMessage: string, userId: number): Promise<string> {
    // Simple mock responses
    const responses = [
      "Thanks for your message! I'm a mock bot. Enable OpenAI plugin for real AI responses.",
      "Interesting! To get real AI responses, add the OpenAI plugin to your project.",
      "I understand. This is a mock response - configure OpenAI for actual AI chat!",
      "Great question! For AI-powered answers, enable the OpenAI integration plugin."
    ]
    
    return responses[Math.floor(Math.random() * responses.length)]
  }
`
  
  return `/**
 * Generated by SSOT CodeGen - Chat Service
 * Business logic for chatbot with ${hasOpenAI ? 'OpenAI' : 'mock'} integration
 */

import prisma from './db.js'
${openAIImport}

export class ChatService {${openAIInit}
  /**
   * Save a message to database
   */
  async saveMessage(data: {
    content: string
    senderId: number
    isBot: boolean
  }) {
    return await prisma.${messageModel.nameLower}.create({
      data: {
        content: data.content,
        senderId: data.senderId,
        isBot: data.isBot,
        timestamp: new Date()
      },
      include: {
        sender: true
      }
    })
  }
  ${botResponseMethod}
  /**
   * Get message history
   */
  async getMessageHistory(options: {
    userId?: number
    limit?: number
  }) {
    return await prisma.${messageModel.nameLower}.findMany({
      where: options.userId ? {
        OR: [
          { senderId: options.userId },
          { isBot: true }
        ]
      } : undefined,
      orderBy: {
        timestamp: 'asc'
      },
      take: options.limit || 50,
      include: {
        sender: true
      }
    })
  }
}
`
}

/**
 * Update app.ts to include chat routes
 */
function updateAppWithChatRoutes(projectPath: string, framework: string): void {
  const appPath = path.join(projectPath, 'src', 'app.ts')
  
  if (!fs.existsSync(appPath)) {
    return
  }
  
  let appContent = fs.readFileSync(appPath, 'utf-8')
  
  if (framework === 'express') {
    // Add import
    if (!appContent.includes('chatRouter')) {
      const importLine = "import { chatRouter } from './routes/chat.js'\n"
      appContent = appContent.replace(
        /import .* from .*\n/g,
        (match) => match
      )
      appContent = importLine + appContent
    }
    
    // Add route
    if (!appContent.includes('app.use(\'/api\', chatRouter)')) {
      appContent = appContent.replace(
        /app\.get\('\/'/,
        `app.use('/api', chatRouter)\n\napp.get('/'`
      )
    }
  } else {
    // Fastify
    if (!appContent.includes('chatRoutes')) {
      const importLine = "import { chatRoutes } from './routes/chat.js'\n"
      appContent = importLine + appContent
    }
    
    if (!appContent.includes('fastify.register(chatRoutes)')) {
      appContent = appContent.replace(
        /await fastify\.register\(cors\)/,
        `await fastify.register(cors)\nawait fastify.register(chatRoutes)`
      )
    }
  }
  
  fs.writeFileSync(appPath, appContent)
}

